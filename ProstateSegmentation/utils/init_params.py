"""initialize parameters for constructing & training network"""


class InitParams:
    """Initializer"""
    dataset = 'PROMISE'
    resumed_epoch = 1210
    run_id = 560
    gpu_id = 0
    split = 0
    epochs = 2500
    activation = 'leaky'
    lr_scheduler = None
    transforms_list_idx = [10, 11, 15]
    use_ADC = True
    use_multi_branches = False
    use_ADC_only = False
    val_only = True
    show_val = True
    display_img = False
    coor_maps = True
    zcoor_maps = None  # 3 statuses: False, True and None (None means zcoor_maps is not included in the input)
    file_suffix = '_full'
    crop_size = 160
    full_size = 400  # size before cropped (loaded from file)
    start_validation = 0
    # dir_in = r"F:\Minh\mxnet\projects\prostate_segmentation\inputs\NIH/"
    T2_ADC_run = 21
    T2_ADC_epoch = 55
    train_batch_size = 2
    val_batch_size = 1
    zdim = 22
    already_normed = True
    norm_thr = .98
    num_slices_each_end = 4
    mid_len_ratio = .8
    min_lr = 5e-5
    max_lr = 5e-2
    mean_scaling = .95
    # crop_size_list = [80, 160, 240]
    crop_size_list = [160, ]
    center_translation_cov = [[30, 0], [0, 30]]
    dense_forward = False
    dir_in = r'F:\Minh\projects\T2_ADC\CycleGAN\results\T2_ADC_run%d\test_%d/' % (T2_ADC_run, T2_ADC_epoch)
    dir_in_tmp = r'F:\Minh\projects\PROMISE2012\T2_ADC\im_matched\training\npy/'
    dir_out = "E:\BACKUPS\%s\outputs/run%d/" % (dataset, run_id)
    dir_fig = '{:s}/figures/'.format(dir_out)
    dir_out_vols = '{:s}/vols_{:04d}/'.format(dir_out, resumed_epoch)
    dir_retrieved_file = None
    retrieved_params = None
    log_file = 'log.txt'
    training_data_name = "im_normed"
    training_gt_name = "lab"
    norm_data = False
    im = None
    lab = None
    train_idx = None
    val_idx = None
    test_idx = None
    train_amount = 100
    val_amount = 50
    test_batch_size = 6
    train_iter = None
    val_iter = None
    test_iter = None
    ctx = None
    net = None
    to_review_network = False
    optimizer = 'sgd'
    base_lr = 1e-4
    wd = .0000
    optimizer_params = None
    Trainer = None
    model = None
    prefix = "dmnet"
    save_interval = 1
    val_interval = 1
    steps = 100000
    log_interval = 4
    loss_term = 'DiceLoss'  # CrossEntropy DiceLoss
    loss = None
    seed = 1
    max_angle = 90
    label_in_last_channel = True
    is_val = None  #  set is_val to True so no data augmentation is implemented when we split the dataset
    translate_ratio = .1